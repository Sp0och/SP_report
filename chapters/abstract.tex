\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
%\chapter*{Zusammenfassung}
%\addcontentsline{toc}{chapter}{Zusammenfassung}

% My endeavour in this thesis was to combine state-of-the-art computer vision methods 
% with the new possibilities that the denser LiDAR sensors provide us with in order to achieve motion estimation. To do so I made use of detected 2D visual features on projected LiDAR data in order to establish point correspondences on subsequent frames. These matches could then be used for the closed form solution to solve the point cloud alignment problem.
% I also put emphasis on researching different feature extraction and descriptor methods (ORB, BRISK, KLT..) and the comparison of their performance on the projections of the different kinds of complementary data considered.

This project aimed at paving the way for the creation of a high level remote control for autonomous excavators using a handheld augmented reality device. The goal was to provide the necessary building blocks for a handheld remote control to fullfil the task of feeding an input to the excavator. The main requirements needed are a way of sharing information between the two devices and solving the colocalization problem between the reference frames. After failed previous attempts of establishing the data transfer using a ROS connection between the two devices the focus in this work lied on making use of the already implemented excavator setup.