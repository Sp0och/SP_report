\chapter{Introduction}
\label{sec:introduction}
%\chapter{Einleitung}
%\label{sec:einleitung}

% Motion estimation is a well known problem in the robotics world and has been worked on by many brilliant people over a lot of time. Traditionally cameras were used to estimate the robots position however also LiDAR sensors are an option. Now with the newest generation of LiDAR sensors we have a tool 
% at our hands that provides us with scans of 128 pixels vertically distributed and 
% perceives a wider field of view which enables much more dense projections of 
% the point cloud data. 

% A challenge when using LiDAR data at real-time has always been the vast amount of information that the processor has to deal with leading to a necessity of downsampling. This problem is even enhanced for these denser scans which would have to be downsampled even more in order to achieve real-time performance and thus lose a lot of valuable data. 

% An idea to counteract this problem while preserving the advantages of the newer generation LiDAR scans is using 2D methods. It is fair to say that 2D computer vision methods are better researched and are faster than iterative 3D point handling methods. So an approach could be to consider the scanned dense 3D data as 2D data through projections in order to then apply fast and refined 2D methods to establish point correspondences and thus be able to apply the closed form solution to the motion estimation problem.



When operating an excavator in the conventional fashion two requirements are imperative: \begin{itemize}
    \item The view onto the construction site
    \item The handles necessary to give inputs to the machine
\end{itemize}
In the case of an autonomous excavator the low level actions to perform are determined by the machine itself, given a high level action input. So in this case the second requirement becomes the possibility to give such a high level input to the system.

With the desired handheld remote control setup the necessity of sharing information between the device and the machine still persists. The visual requirements change however. From the handheld camera we now receive the required view of the surroundings on the construction site but in order to successfully share a geometric location with the excavator the colocalization problem has to be solved for the two players. Having an AR remote control integrated in a handheld device also provides the possibility of introducing further useful features such as displaying a preview of an action of choice. 

In this project I attempted to overcome the key challenges constituting the requirements mentioned above. 

The plan was to solve the data transfer requirement utilizing the already implemented Unreal Engine setup of the autonomous excavator from the Robotic Systems Laboratory. To account for the colocalization problem an approach using Microsoft's Azure Spatial Anchors was used.